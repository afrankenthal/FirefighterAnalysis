{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# import operator\n",
    "import sys\n",
    "import time\n",
    "# from collections import OrderedDict\n",
    "# from functools import reduce\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "# from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "# from skhep.visual import MplPlotter as skh_plt\n",
    "\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "\n",
    "from XRootD import client\n",
    "from XRootD.client.flags import DirListFlags, StatInfoFlags, OpenFlags, MkDirFlags, QueryCode\n",
    "# import xrdfs_find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import local classes from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify\n",
    "%autonotify -a 10\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils.ObjectExtractor\n",
    "%aimport utils.PlotMaker\n",
    "%aimport utils.HistogramContainer\n",
    "%aimport utils.HistogramCalculator\n",
    "OE = utils.ObjectExtractor\n",
    "PM = utils.PlotMaker\n",
    "HCont = utils.HistogramContainer\n",
    "HCalc = utils.HistogramCalculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(sys.version_info)\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "# print(num_cores)\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(48)\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['grid.linestyle'] = ':'\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "numCuts = np.arange(0,6)\n",
    "\n",
    "branch_path = 'SREffi_gbm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plot_vars = ['metpt', 'jetpt','metjetphi', 'metmuphi', 'leadingmupt', 'subleadingmupt', 'recodr', 'recovertex']\n",
    "plot_vars_metjet = all_plot_vars[0:4] #['metpt', 'jetpt', 'metjetphi', 'metmuphi']\n",
    "plot_vars_muons = all_plot_vars[4:8] #['leadingmupt', 'subleadingmupt', 'recodr', 'recovertex']\n",
    "cutflow_vars = ['cutflow_incl', 'cutflow_excl']\n",
    "all_plot_xlabels = [\n",
    "    'MET [GeV]', 'Leading jet pT [GeV]', '$\\Delta\\Phi$(MET, jet)', '$\\Delta\\Phi$(MET, di-muon)',\n",
    "    'Leading muon pT [GeV]', 'Subleading muon pT [GeV]', 'dR(muons)', 'Di-muon vertex [cm]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "histos = {}\n",
    "all_bins = {}\n",
    "for plot_var in all_plot_vars:\n",
    "    histos[plot_var] = {}\n",
    "    all_bins[plot_var] = 60\n",
    "histos['cutflow_incl'] = {}\n",
    "histos['cutflow_excl'] = {}\n",
    "histos['sumgenwgt'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/bkgs.json') as bkgs_json_file:\n",
    "    bkgs = json.load(bkgs_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QCD_bkgs = {bkg:bkgs[bkg] for bkg in bkgs if 'QCD' in bkg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrdfs = client.FileSystem(\"root://cmseos.fnal.gov/\")\n",
    "\n",
    "# redirector = 'root://cmsxrootd.fnal.gov'\n",
    "redirector = 'root://cmseos.fnal.gov'\n",
    "bkg_base_dir = '/store/group/lpcmetx/iDM/Ntuples/2018/backgrounds'\n",
    "files = {}\n",
    "\n",
    "for bkg, properties in QCD_bkgs.items():\n",
    "    files[bkg] = []\n",
    "    status, listing = xrdfs.dirlist(f'{bkg_base_dir}/{properties[\"dir\"]}', DirListFlags.STAT)\n",
    "    for file in listing:\n",
    "        if '.root' in file.name:\n",
    "            files[bkg].append(f'{redirector}/{bkg_base_dir}/{properties[\"dir\"]}/{file.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('QCD_bEnriched_HT100to200', 82),\n",
       " ('QCD_bEnriched_HT200to300', 63),\n",
       " ('QCD_bEnriched_HT300to500', 13),\n",
       " ('QCD_bEnriched_HT500to700', 24),\n",
       " ('QCD_bEnriched_HT700to1000', 11),\n",
       " ('QCD_bEnriched_HT1000to1500', 1),\n",
       " ('QCD_bEnriched_HT1500to2000', 1),\n",
       " ('QCD_bEnriched_HT2000toINF', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_files_total = np.sum(np.array([len(files[i]) for i in files]))\n",
    "print(num_files_total)\n",
    "[(i, len(files[i])) for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing background QCD_bEnriched_HT100to200 (1/8)\n",
      "Reading file 1 of 82, global 1 of 196 (0.00%)\n",
      "Reading file 11 of 82, global 11 of 196 (5.10%)\n",
      "Reading file 21 of 82, global 21 of 196 (10.20%)\n",
      "Processing background QCD_bEnriched_HT200to300 (2/8)\n",
      "Reading file 1 of 63, global 31 of 196 (15.31%)\n",
      "Reading file 11 of 63, global 41 of 196 (20.41%)\n",
      "Reading file 21 of 63, global 51 of 196 (25.51%)\n",
      "Processing background QCD_bEnriched_HT300to500 (3/8)\n",
      "Reading file 1 of 13, global 61 of 196 (30.61%)\n",
      "Reading file 11 of 13, global 71 of 196 (35.71%)\n",
      "Processing background QCD_bEnriched_HT500to700 (4/8)\n",
      "Reading file 1 of 24, global 74 of 196 (37.24%)\n",
      "Reading file 11 of 24, global 84 of 196 (42.35%)\n",
      "Reading file 21 of 24, global 94 of 196 (47.45%)\n",
      "Processing background QCD_bEnriched_HT700to1000 (5/8)\n",
      "Reading file 1 of 11, global 98 of 196 (49.49%)\n",
      "Reading file 11 of 11, global 108 of 196 (54.59%)\n",
      "Processing background QCD_bEnriched_HT1000to1500 (6/8)\n",
      "Reading file 1 of 1, global 109 of 196 (55.10%)\n",
      "Processing background QCD_bEnriched_HT1500to2000 (7/8)\n",
      "Reading file 1 of 1, global 110 of 196 (55.61%)\n",
      "Processing background QCD_bEnriched_HT2000toINF (8/8)\n",
      "Reading file 1 of 1, global 111 of 196 (56.12%)\n",
      "CPU times: user 13min 12s, sys: 59.5 s, total: 14min 11s\n",
      "Wall time: 25min 20s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"1ecb412a-eec1-418c-a7c7-303fe058d383\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"1ecb412a-eec1-418c-a7c7-303fe058d383\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"10\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# MAX_FILES=None # To load all files\n",
    "MAX_FILES=30 # For testing\n",
    "\n",
    "### Initialize empty dicts of histograms \n",
    "# histos = {}\n",
    "# all_bins = {}\n",
    "# for plot_var in all_plot_vars:\n",
    "#     histos[plot_var] = {}\n",
    "#     all_bins[plot_var] = 60\n",
    "# histos['cutflow_incl'] = {}\n",
    "# histos['cutflow_excl'] = {}\n",
    "# histos['sumgenwgt'] = {}\n",
    "\n",
    "global_file_counter = 1\n",
    "\n",
    "objects = {}\n",
    "\n",
    "for bkg in QCD_bkgs:\n",
    "    objects[bkg] = {}\n",
    "    \n",
    "    print(f'Processing background {bkg} ({(list(QCD_bkgs.keys())).index(bkg)+1}/{len(QCD_bkgs)})')\n",
    "    \n",
    "    ### Initialize histograms as empty HistogramContainers\n",
    "    for plot_var in all_plot_vars:\n",
    "        histos[plot_var][bkg] = HCont.HistogramContainer(all_bins[plot_var])\n",
    "    histos['cutflow_incl'][bkg] = np.zeros(len(numCuts))\n",
    "    histos['cutflow_excl'][bkg] = np.zeros(len(numCuts))\n",
    "    histos['sumgenwgt'][bkg] = 0.0\n",
    "    \n",
    "    ### Load data\n",
    "    file_counter = 1\n",
    "    for file in files[bkg][slice(0,MAX_FILES)]:\n",
    "        \n",
    "        if file_counter % 10 == 1:\n",
    "            print(f'Reading file {file_counter} of {len(files[bkg])},'\n",
    "                  f' global {global_file_counter} of {num_files_total}'\n",
    "                  f' ({100*(global_file_counter-1)/num_files_total:.2f}%)')\n",
    "#             with open('histos_gbm.dat', 'wb') as histos_file:\n",
    "#                 pickle.dump(histos, histos_file)\n",
    "        file_counter += 1\n",
    "        global_file_counter += 1\n",
    "        \n",
    "        ### Open ROOT file and get tree\n",
    "        tree = uproot.open(file)[branch_path + '/cutsTree']\n",
    "        \n",
    "        ### Make pandas dataframes and create all objects that will be passed to histo functions\n",
    "        obj_extractor = OE.ObjectExtractor(tree)\n",
    "        objects[bkg][file] = obj_extractor.get_all()\n",
    "            \n",
    "        ## Add to sum of genwgts\n",
    "        histos['sumgenwgt'][bkg] += np.sum(objects[bkg][file]['genwgt'])\n",
    "        \n",
    "        ### Calculate histograms and cutflows\n",
    "        histo_maker = HCalc.HistogramCalculator(objects[bkg][file], bkg)\n",
    "            \n",
    "        ### Cutflows\n",
    "        incl, excl = histo_maker.cutflows()\n",
    "        histos['cutflow_incl'][bkg] += incl\n",
    "        histos['cutflow_excl'][bkg] += excl\n",
    "        \n",
    "        ### Histograms\n",
    "        for plot_var in all_plot_vars:\n",
    "            new_hist = eval(f'histo_maker.{plot_var}()')\n",
    "            histos[plot_var][bkg] += new_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "luminosity = 59.97 # 1/fb, 2018\n",
    "for bkg, properties in QCD_bkgs.items():\n",
    "    properties['weight'] = luminosity * properties['xsec'] / histos['sumgenwgt'][bkg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Helper functions to calculate average angles\n",
    "# This takes a few seconds to run, since we\n",
    "# are using the apply method\n",
    "\n",
    "def parallelize(data, func):\n",
    "#     data_split = np.array_split(data, partitions)\n",
    "    pool = multiprocessing.Pool(int(num_cores/2))\n",
    "#     data = pd.concat(pool.map(func, data_split))\n",
    "    data = pd.concat(pool.map(func, [group for name, group in data]))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def calcAvgAngle(group):\n",
    "    # FIXME need to ensure at least 2 muons (otherwise index -1 == 0)\n",
    "    x = np.cos(group['recoPhi'].iloc[0]) + np.cos(group['recoPhi'].iloc[-1])\n",
    "    y = np.sin(group['recoPhi'].iloc[0]) + np.sin(group['recoPhi'].iloc[-1])\n",
    "    return math.atan2(y/2, x/2)\n",
    "\n",
    "def func_group_apply(df):\n",
    "    # Applies above function on event-by-event basis\n",
    "    return df.groupby('entry').apply(calcAvgAngle)\n",
    "\n",
    "def reducephi(row):\n",
    "    # Helper function to normalize angle differences to [-Pi, Pi]\n",
    "    # cond: if abs(phidiff) > Pi => phidiff = phidiff - 2*Pi*sign(phidiff)\n",
    "    if abs(row) > math.pi:\n",
    "        return row - 2*math.pi*(row/abs(row))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hist2d(df, var1, var2, cut=0, **kwargs):\n",
    "        # Given a dataframe for some observable, adds the\n",
    "        # gen weight and computes the histogram for it\n",
    "        if 'bins' not in kwargs:\n",
    "            kwargs['bins'] = 30\n",
    "\n",
    "#         temp_df = pd.concat([variables_df, self.genwgt], axis=1).dropna()\n",
    "        df['genwgt_sqrd'] = df['genwgt']**2\n",
    "        counts = {}; edges_x = {}; edges_y = {}; wgt_sqrd = {}\n",
    "#         for cut in numCuts:\n",
    "#             cuts_to_apply = slice(None) if self.cuts_crit is None else reduce(operator.and_, self.cuts_crit[0:cut+1])\n",
    "        kwargs['weights'] = df['genwgt']\n",
    "        counts[cut], edges_x[cut], edges_y[cut] = np.histogram2d(df[var1], df[var2], **kwargs)\n",
    "            # Digitizes data to find out which bin of histogram each row falls in\n",
    "        bin_idxs_x = np.digitize(df[var1], edges_x[cut])\n",
    "        bin_idxs_y = np.digitize(df[var2], edges_y[cut])\n",
    "#             bin_idxs = np.digitize(temp_df[cuts_to_apply][variable_df.name], edges[cut])\n",
    "        df['bin_idx_x'] = pd.Series(bin_idxs_x)\n",
    "        df['bin_idx_y'] = pd.Series(bin_idxs_y)\n",
    "            # Uses indexes from above to sum the gen weights squared (for errors)\n",
    "        wgt_sqrd[cut] = df.groupby(['bin_idx_x', 'bin_idx_y']).sum()['genwgt_sqrd']\n",
    "        return list(zip(counts.values(), edges_x.values(), edges_y.values(), wgt_sqrd.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hist2d(variables_df, var_name1, var_name2, **kwargs):\n",
    "        # Given a dataframe for some observable, adds the\n",
    "        # gen weight and computes the histogram for it\n",
    "        if 'bins' not in kwargs:\n",
    "            kwargs['bins'] = 30\n",
    "#             kwargs['range'] = ((0,6), (0, 20))\n",
    "#             kwargs['range'] = ((-math.pi,math.pi), (0,6))\n",
    "\n",
    "#         temp_df = pd.concat([variables_df, self.genwgt], axis=1).dropna()\n",
    "#         temp_df['genwgt_sqrd'] = temp_df['genwgt']**2\n",
    "        counts = {}; edges_x = {}; edges_y = {}; wgt_sqrd = {}\n",
    "        for cut in numCuts:\n",
    "#             cuts_to_apply = slice(None) if self.cuts_crit is None else reduce(operator.and_, self.cuts_crit[0:cut+1])\n",
    "            kwargs['weights'] = variables_df['genwgt']\n",
    "            counts[cut], edges_x[cut], edges_y[cut] = np.histogram2d(variables_df[var_name1], variables_df[var_name2], **kwargs)\n",
    "            # Digitizes data to find out which bin of histogram each row falls in\n",
    "#             bin_idxs = np.digitize(temp_df[cuts_to_apply][variable_df.name], edges[cut])\n",
    "#             temp_df['bin_idx'] = pd.Series(bin_idxs)\n",
    "            # Uses indexes from above to sum the gen weights squared (for errors)\n",
    "#             wgt_sqrd[cut] = np.sum(temp_df.groupby('bin_idx'))['genwgt_sqrd']\n",
    "        return list(zip(counts.values(), edges_x.values(), edges_y.values()))#, wgt_sqrd.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binned_data_2d(axis, bin_edges_x, bin_edges_y, data, *args, **kwargs):\n",
    "    #The dataset values are the bin centres\n",
    "    x = (bin_edges_x[1:] + bin_edges_x[:-1]) / 2.0\n",
    "    y = (bin_edges_y[1:] + bin_edges_y[:-1]) / 2.0\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    #The weights are the y-values of the input binned data\n",
    "    weights = data.flatten()\n",
    "    return axis.hist2d(x=X.flatten(), y=Y.flatten(), bins=[bin_edges_x,bin_edges_y], weights=weights, *args, **kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ratio_slices(data, slices, ratio_divisor, orientation):\n",
    "    if orientation == 'horizontal':\n",
    "        x_slice_bins = np.digitize(slices, data[2])\n",
    "        y_ratio_div_bin = np.digitize(ratio_divisor, data[1])\n",
    "        \n",
    "        integrals_low = [np.sum(np.diff(data[2][x_slice_bin-1:x_slice_bin+1])*\n",
    "                                np.diff(data[1][0:y_ratio_div_bin+1])*\n",
    "                                data[0][x_slice_bin][0:y_ratio_div_bin]) for x_slice_bin in x_slice_bins]\n",
    "        \n",
    "        errors_low = [np.sum(np.diff(data[2][x_slice_bin-1:x_slice_bin+1])*\n",
    "                             np.diff(data[1][0:y_ratio_div_bin+1])*\n",
    "                             np.sqrt(data[3][x_slice_bin][0:y_ratio_div_bin])) for x_slice_bin in x_slice_bins]\n",
    "        \n",
    "        integrals_high = [np.sum(np.diff(data[2][x_slice_bin-1:x_slice_bin+1])*\n",
    "                                 np.diff(data[1][y_ratio_div_bin:])*\n",
    "                                 data[0][x_slice_bin][y_ratio_div_bin:]) for x_slice_bin in x_slice_bins]\n",
    "        \n",
    "        errors_high = [np.sum(np.diff(data[2][x_slice_bin-1:x_slice_bin+1])*\n",
    "                              np.diff(data[1][y_ratio_div_bin:])*\n",
    "                              np.sqrt(data[3][x_slice_bin][y_ratio_div_bin:])) for x_slice_bin in x_slice_bins]\n",
    "        \n",
    "    elif orientation == 'vertical':\n",
    "        y_slice_bins = np.digitize(slices, data[1])\n",
    "        x_ratio_div_bin = np.digitize(ratio_divisor, data[2])\n",
    "        \n",
    "        integrals_low = [np.sum(np.diff(data[2][0:x_ratio_div_bin+1])*\n",
    "                                np.diff(data[1][y_slice_bin-1:y_slice_bin+1])*\n",
    "                                data[0][0:x_ratio_div_bin,y_slice_bin]) for y_slice_bin in y_slice_bins]\n",
    "        \n",
    "        errors_low = [np.sum(np.diff(data[2][0:x_ratio_div_bin+1])*\n",
    "                             np.diff(data[1][y_slice_bin-1:y_slice_bin+1])*\n",
    "                             np.sqrt(data[3].loc[1:x_ratio_div_bin, y_slice_bin])) for y_slice_bin in y_slice_bins]\n",
    "        \n",
    "        integrals_high = [np.sum(np.diff(data[2][x_ratio_div_bin:])*\n",
    "                                 np.diff(data[1][y_slice_bin-1:y_slice_bin+1])*\n",
    "                                 data[0][x_ratio_div_bin:,y_slice_bin]) for y_slice_bin in y_slice_bins]\n",
    "        \n",
    "        errors_high = [np.sum(np.diff(data[2][x_ratio_div_bin:])*\n",
    "                              np.diff(data[1][y_slice_bin-1:y_slice_bin+1])*\n",
    "                              np.sqrt(data[3].loc[x_ratio_div_bin+1:30,y_slice_bin])) for y_slice_bin in y_slice_bins]\n",
    "        \n",
    "    if np.sum(integrals_low) > np.sum(integrals_high):\n",
    "        ratio = np.divide(integrals_high, integrals_low)\n",
    "    else:\n",
    "        ratio = np.divide(integrals_low, integrals_high)\n",
    "        \n",
    "    error_ratio = ratio * (np.divide(errors_high,integrals_high) + np.divide(errors_low, integrals_low))\n",
    "    \n",
    "    return (ratio, error_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "histogram2d() got an unexpected keyword argument 'cut'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f234fcb855f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduced_angle_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vertex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recoVxy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genwgt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQCD_bkgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcurrent_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_hist2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reducedAngleDiff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recoVxy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_hist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtotal_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-af12028f8aef>\u001b[0m in \u001b[0;36mcompute_hist2d\u001b[0;34m(variables_df, var_name1, var_name2, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             cuts_to_apply = slice(None) if self.cuts_crit is None else reduce(operator.and_, self.cuts_crit[0:cut+1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genwgt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Digitizes data to find out which bin of histogram each row falls in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#             bin_idxs = np.digitize(temp_df[cuts_to_apply][variable_df.name], edges[cut])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: histogram2d() got an unexpected keyword argument 'cut'"
     ]
    }
   ],
   "source": [
    "total_hist = None\n",
    "total_df = pd.DataFrame()\n",
    "\n",
    "for bkg in objects:\n",
    "    for file, obj in objects[bkg].items():\n",
    "\n",
    "        muons = obj['muons'].reset_index()\n",
    "        muons['data_chunk'] = muons['entry'].mod(int(num_cores * 3 / 2)) # num_cores/2 * 3 chunks/core\n",
    "        muons = muons.set_index(['entry'])\n",
    "        # Here, group by data_chunk instead of entry, inside func_group_apply\n",
    "        # we also have a groupby('entry')\n",
    "        avg_muon_angle = parallelize(muons.groupby('data_chunk'), func_group_apply)\n",
    "        angle_diff = (obj['MET']['recoPFMetPhi'].dropna() - avg_muon_angle).dropna()\n",
    "        reduced_angle_diff = np.abs(angle_diff.apply(reducephi).dropna())\n",
    "        reduced_angle_diff.name = 'reducedAngleDiff'\n",
    "\n",
    "        df = pd.concat([reduced_angle_diff, obj['vertex']['recoVxy'], obj['genwgt']*QCD_bkgs[bkg]['weight']], axis=1).dropna()\n",
    "        total_df = pd.concat([total_df, df], ignore_index=True)\n",
    "        current_hist = compute_hist2d(df, 'reducedAngleDiff', 'recoVxy', cut=0, range=((0,math.pi),(0,30)));\n",
    "        if total_hist is None:\n",
    "            total_hist = current_hist[0][0]\n",
    "            total_wgt_sqrd = current_hist[0][3]\n",
    "        else:\n",
    "            total_hist += current_hist[0][0]\n",
    "            total_wgt_sqrd = total_wgt_sqrd.add(current_hist[0][3], fill_value=0)\n",
    "\n",
    "total_wgt_sqrd = total_wgt_sqrd.reindex(pd.MultiIndex.from_product([np.arange(1,31), np.arange(1,31)]), fill_value=0)\n",
    "            \n",
    "plot_binned_data_2d(plt, current_hist[0][2], current_hist[0][1], total_hist, norm=mpl.colors.LogNorm());\n",
    "plt.colorbar()\n",
    "plt.xlabel('muons vxy [cm]')\n",
    "plt.ylabel(r'|$\\Delta\\Phi$(MET, muons)|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XSliceVals = [1,5,10,15,20,25,28]\n",
    "YDivVal = 0.5\n",
    "ratio, err = calc_ratio_slices([total_hist, current_hist[0][1], current_hist[0][2], total_wgt_sqrd], XSliceVals, YDivVal, 'horizontal')\n",
    "\n",
    "plt.errorbar(XSliceVals, ratio, xerr=[np.diff(current_hist[0][2][0:2])]*len(ratio), yerr=err, fmt='ro')\n",
    "plt.ylim([0.0,.05])\n",
    "plt.xlabel(\"muons vxy [cm]\")\n",
    "plt.ylabel(\"ratio low/high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YSliceVals = [0.5,1.0,1.5,2.0,2.5,2.8]\n",
    "XDivVal = 10\n",
    "ratio, err = calc_ratio_slices([total_hist, current_hist[0][1], current_hist[0][2], total_wgt_sqrd], YSliceVals, XDivVal, 'vertical')\n",
    "\n",
    "plt.errorbar(YSliceVals, ratio, xerr=[np.diff(current_hist[0][1][0:2])]*len(ratio), yerr=err, fmt='yo')\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.xlabel(r'|$\\Delta\\Phi$(MET, muons)|')\n",
    "plt.ylabel(\"ratio low/high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df[['reducedAngleDiff','recoVxy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hist = None\n",
    "\n",
    "for bkg in objects:\n",
    "    for file, obj in objects[bkg].items():\n",
    "\n",
    "        muons = obj['muons'].reset_index()\n",
    "        muons['data_chunk'] = muons['entry'].mod(int(num_cores * 3 / 2)) # num_cores/2 * 3 chunks/core\n",
    "        muons = muons.set_index(['entry'])\n",
    "        # Here, group by data_chunk instead of entry, inside func_group_apply\n",
    "        # we also have a groupby('entry')\n",
    "        avg_muon_angle = parallelize(muons.groupby('data_chunk'), func_group_apply)\n",
    "        angle_diff = (obj['MET']['recoPFMetPhi'].dropna() - avg_muon_angle).dropna()\n",
    "        reduced_angle_diff = np.abs(angle_diff.apply(reducephi).dropna())\n",
    "        reduced_angle_diff.name = 'reducedAngleDiff'\n",
    "\n",
    "        df = pd.concat([reduced_angle_diff, obj['vertex']['recoDr'], obj['genwgt']*QCD_bkgs[bkg]['weight']], axis=1).dropna()\n",
    "        current_hist = compute_hist2d(df, 'reducedAngleDiff', 'recoDr', cut=0, range=((0,math.pi),(0,6)));\n",
    "        if total_hist is None:\n",
    "            total_hist = current_hist[0][0]\n",
    "            total_wgt_sqrd = current_hist[0][3]\n",
    "        else:\n",
    "            total_hist += current_hist[0][0]\n",
    "            total_wgt_sqrd = total_wgt_sqrd.add(current_hist[0][3], fill_value=0)\n",
    "\n",
    "total_wgt_sqrd = total_wgt_sqrd.reindex(pd.MultiIndex.from_product([np.arange(1,31), np.arange(1,31)]), fill_value=0)\n",
    "    \n",
    "plot_binned_data_2d(plt, current_hist[0][2], current_hist[0][1], total_hist)#, norm=mpl.colors.LogNorm());\n",
    "plt.colorbar()\n",
    "plt.xlabel('muons dR')\n",
    "plt.ylabel(r'|$\\Delta\\Phi$(MET, muons)|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XSliceVals = [0.2,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]\n",
    "YDivVal = 0.5\n",
    "ratio, err = calc_ratio_slices([total_hist, current_hist[0][1], current_hist[0][2], total_wgt_sqrd], XSliceVals, YDivVal, 'horizontal')\n",
    "\n",
    "plt.errorbar(XSliceVals, ratio, xerr=[np.diff(current_hist[0][2][0:2])]*len(ratio), yerr=err, fmt='ro')\n",
    "plt.ylim([0.0,.5])\n",
    "plt.xlabel(\"muons dR\")\n",
    "plt.ylabel(\"ratio low/high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YSliceVals = [0.5,1.0,1.5,2.0,2.5,2.8]\n",
    "XDivVal = 0.8\n",
    "ratio, err = calc_ratio_slices([total_hist, current_hist[0][1], current_hist[0][2], total_wgt_sqrd], YSliceVals, XDivVal, 'vertical')\n",
    "\n",
    "plt.errorbar(YSliceVals, ratio, xerr=[np.diff(current_hist[0][1][0:2])]*len(ratio), yerr=err, fmt='yo')\n",
    "plt.ylim([0.0,.5])\n",
    "plt.xlabel(r'|$\\Delta\\Phi$(MET, muons)|')\n",
    "plt.ylabel(\"ratio low/high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['recoDr'], df['reducedAngleDiff'], rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hist = None\n",
    "\n",
    "for bkg in objects:\n",
    "    for file, obj in objects[bkg].items():\n",
    "\n",
    "        df = pd.concat([obj['vertex']['recoDr'], obj['vertex']['recoVxy'], obj['genwgt']*QCD_bkgs[bkg]['weight']], axis=1).dropna()\n",
    "        current_hist = compute_hist2d(df, 'recoDr', 'recoVxy', cut=0, range=((0,6),(0,20)));\n",
    "        if total_hist is None:\n",
    "            total_hist = current_hist[0][0]\n",
    "            total_wgt_sqrd = current_hist[0][3]\n",
    "        else:\n",
    "            total_hist += current_hist[0][0]\n",
    "            total_wgt_sqrd = total_wgt_sqrd.add(current_hist[0][3], fill_value=0)\n",
    "            \n",
    "total_wgt_sqrd = total_wgt_sqrd.reindex(pd.MultiIndex.from_product([np.arange(1,31), np.arange(1,31)]), fill_value=0)\n",
    "    \n",
    "plot_binned_data_2d(plt, current_hist[0][2], current_hist[0][1], total_hist, norm=mpl.colors.LogNorm());\n",
    "plt.colorbar()\n",
    "plt.xlabel('muons vxy')\n",
    "plt.ylabel('muons dR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XSliceVals = [1,5,10,15,18]\n",
    "YDivVal = 0.8\n",
    "ratio, err = calc_ratio_slices([total_hist, current_hist[0][1], current_hist[0][2], total_wgt_sqrd], XSliceVals, YDivVal, 'horizontal')\n",
    "\n",
    "plt.errorbar(XSliceVals, ratio, xerr=[np.diff(current_hist[0][2][0:2])]*len(ratio), yerr=err, fmt='ro')\n",
    "plt.ylim([0.0,.5])\n",
    "plt.xlabel(\"muons vxy [cm]\")\n",
    "plt.ylabel(\"ratio low/high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YSliceVals = [0.1,0.5,1.0,1.5,2.0,3.0,4.0]\n",
    "XDivVal = 10\n",
    "ratio, err = calc_ratio_slices([total_hist, current_hist[0][1], current_hist[0][2], total_wgt_sqrd], YSliceVals, XDivVal, 'vertical')\n",
    "\n",
    "plt.errorbar(YSliceVals, ratio, xerr=[np.diff(current_hist[0][1][0:2])]*len(ratio), yerr=err, fmt='yo')\n",
    "plt.ylim([0.0,.7])\n",
    "plt.xlabel(\"muons dR\")\n",
    "plt.ylabel(\"ratio low/high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recoDr = pd.Series()\n",
    "for bkg in QCD_bkgs:\n",
    "    for obj in objects[bkg].values():\n",
    "        total_recoDr = pd.concat([total_recoDr, obj['vertex'][['recoDr','recoVxy']]],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_recoDr.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
