{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import concurrent.futures\n",
    "\n",
    "from XRootD import client\n",
    "from XRootD.client.flags import DirListFlags, StatInfoFlags, OpenFlags, MkDirFlags, QueryCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import local classes from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils.ObjectExtractor\n",
    "%aimport utils.PlotMaker\n",
    "%aimport utils.HistogramContainer\n",
    "%aimport utils.HistogramCalculator\n",
    "OE = utils.ObjectExtractor\n",
    "PM = utils.PlotMaker\n",
    "HCont = utils.HistogramContainer\n",
    "HCalc = utils.HistogramCalculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(sys.version_info)\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "# print(num_cores)\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(48)\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['grid.linestyle'] = ':'\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "numCuts = np.arange(0,6)\n",
    "\n",
    "branch_path = 'SREffi_gbm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_plot_vars = ['metpt', 'jetpt','metjetphi', 'metmuphi', 'leadingmupt', 'subleadingmupt', 'recodr', 'recovertex']\n",
    "plot_vars_metjet = all_plot_vars[0:4] #['metpt', 'jetpt', 'metjetphi', 'metmuphi']\n",
    "plot_vars_muons = all_plot_vars[4:8] #['leadingmupt', 'subleadingmupt', 'recodr', 'recovertex']\n",
    "cutflow_vars = ['cutflow_incl', 'cutflow_excl']\n",
    "all_plot_xlabels = [\n",
    "    'MET [GeV]', 'Leading jet pT [GeV]', '$\\Delta\\Phi$(MET, jet)', '$\\Delta\\Phi$(MET, di-muon)',\n",
    "    'Leading muon pT [GeV]', 'Subleading muon pT [GeV]', 'dR(muons)', 'Di-muon vertex [cm]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histos = {}\n",
    "all_bins = {}\n",
    "for plot_var in all_plot_vars:\n",
    "    histos[plot_var] = {}\n",
    "    all_bins[plot_var] = 60\n",
    "histos['cutflow_incl'] = {}\n",
    "histos['cutflow_excl'] = {}\n",
    "histos['sumgenwgt'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masses = [('60p0','20p0'),('6p0','2p0'),('52p5','5p0'),('5p25','0p5')]\n",
    "def print_masses(mass):\n",
    "    return f'({float(mass[0].replace(\"p\",\".\"))-float(mass[1].replace(\"p\",\".\"))/2}, ' + \\\n",
    "           f'{float(mass[0].replace(\"p\",\".\"))+float(mass[1].replace(\"p\",\".\"))/2}) GeV'\n",
    "    \n",
    "mchis = dict([(mass[0], print_masses(mass)) for mass in masses])\n",
    "ctaus = [10]#, 10, 100, 1000]\n",
    "\n",
    "labels = [ f'cut{cut}' for cut in numCuts ]\n",
    "cut_descriptions = [\n",
    "    'cut1: MET/MHT trigger fired (120 GeV)',\n",
    "    'cut2: j1 pT > 120 GeV, <= 2j w/ pT > 30 GeV',\n",
    "    'cut3: mu1 pT > 5 GeV, 0.1 < |dxy| < 700 cm',\n",
    "    'cut4: mu2 pT > 5 GeV, 0.1 < |dxy| < 700 cm',\n",
    "    r'cut5: $|\\Delta\\Phi$(MET, mu pair)| < 0.4',\n",
    "]\n",
    "\n",
    "\n",
    "base_dir = '../Firefighter/washAOD/SROptimization/'\n",
    "def filename(Mchi, dMchi, ctau): \n",
    "    return base_dir + f'Mchi-{Mchi}_dMchi-{dMchi}_ctau-{ctau}.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trees_gbm = dict()\n",
    "gen_info_gbm = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_params = len(masses)*len(ctaus)\n",
    "count_param = 1\n",
    "\n",
    "for (Mchi, dMchi) in masses:\n",
    "    trees_gbm[Mchi] = dict()\n",
    "    gen_info_gbm[Mchi] = dict()\n",
    "    for ctau in ctaus:\n",
    "        gen_info_gbm[Mchi][ctau] = uproot.open(filename(Mchi, dMchi, ctau))['GEN/gen']#.pandas.df(flatten=False)\n",
    "        trees_gbm[Mchi][ctau] = uproot.open(filename(Mchi, dMchi, ctau))[branch_path + f'/cutsTree']#.pandas.df(flatten=False)\n",
    "        print(f'{count_param} of {num_params}: ' + filename(Mchi, dMchi, ctau))\n",
    "        count_param += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histos_signal = {}\n",
    "for plot_var in all_plot_vars:\n",
    "    histos_signal[plot_var] = {}\n",
    "for plot_var in cutflow_vars:\n",
    "    histos_signal[plot_var] = {}\n",
    "    \n",
    "for mchi in mchis:\n",
    "    for plot_var in all_plot_vars:\n",
    "        histos_signal[plot_var][mchi] = HCont.HistogramContainer(all_bins[plot_var])\n",
    "    histos_signal['cutflow_incl'][mchi] = np.zeros(len(numCuts))\n",
    "    histos_signal['cutflow_excl'][mchi] = np.zeros(len(numCuts))\n",
    "        \n",
    "    ### Make pandas dataframes and create all objects that will be passed to histo functions\n",
    "    obj_extractor = OE.ObjectExtractor(trees_gbm[mchi][ctau], mchi)\n",
    "    objects = obj_extractor.get_all()\n",
    "\n",
    "    ### Calculate histograms and cutflows\n",
    "    histo_computer = HCalc.HistogramCalculator(objects, mchi)\n",
    "\n",
    "    ### Cutflows\n",
    "    incl, excl = histo_computer.cutflows()\n",
    "    histos_signal['cutflow_incl'][mchi] += incl\n",
    "    histos_signal['cutflow_excl'][mchi] += excl\n",
    "\n",
    "    ### Histograms\n",
    "    for plot_var in all_plot_vars:\n",
    "        new_hist = eval(f'histo_computer.{plot_var}()')\n",
    "        histos_signal[plot_var][mchi] += new_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('histos_signal_objects_gbm.dat', 'wb') as histos_file:\n",
    "    pickle.dump(histos_signal, histos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('config/bkgs3.json') as bkgs_json_file:\n",
    "    bkgs = json.load(bkgs_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xrdfs = client.FileSystem(\"root://cmseos.fnal.gov/\")\n",
    "\n",
    "redirector = 'root://cmsxrootd.fnal.gov'\n",
    "bkg_base_dir = '/store/group/lpcmetx/iDM/Ntuples/2018/backgrounds'\n",
    "files = {}\n",
    "\n",
    "for bkg, properties in bkgs.items():\n",
    "    files[bkg] = []\n",
    "    status, listing = xrdfs.dirlist(f'{bkg_base_dir}/{properties[\"dir\"]}', DirListFlags.STAT)\n",
    "    for file in listing:\n",
    "        if '.root' in file.name:\n",
    "            files[bkg].append(f'{redirector}/{bkg_base_dir}/{properties[\"dir\"]}/{file.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NoBPTX', 6)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_files_total = np.sum(np.array([len(files[i]) for i in files]))\n",
    "print(num_files_total)\n",
    "[(i, len(files[i])) for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing background NoBPTX (1/1)\n",
      "Reading file 1 of 6, global 1 of 6 (0.00%)\n",
      "Sample \"\" does not have either pileup or weight information\n",
      "Sample \"\" does not have either pileup or weight information\n",
      "Sample \"\" does not have either pileup or weight information\n",
      "Sample \"\" does not have either pileup or weight information\n",
      "Sample \"\" does not have either pileup or weight information\n",
      "Sample \"\" does not have either pileup or weight information\n",
      "CPU times: user 3min 11s, sys: 20.3 s, total: 3min 31s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_FILES=None # To load all possible files\n",
    "# MAX_FILES=1 # For testing\n",
    "\n",
    "### Initialize empty dicts of histograms \n",
    "# histos = {}\n",
    "# all_bins = {}\n",
    "# for plot_var in all_plot_vars:\n",
    "#     histos[plot_var] = {}\n",
    "#     all_bins[plot_var] = 60\n",
    "# histos['cutflow_incl'] = {}\n",
    "# histos['cutflow_excl'] = {}\n",
    "# histos['sumgenwgt'] = {}\n",
    "\n",
    "global_file_counter = 1\n",
    "\n",
    "for bkg in bkgs:\n",
    "    \n",
    "    print(f'Processing background {bkg} ({(list(bkgs.keys())).index(bkg)+1}/{len(bkgs)})')\n",
    "    \n",
    "    ### Initialize histograms as empty HistogramContainers\n",
    "    for plot_var in all_plot_vars:\n",
    "        histos[plot_var][bkg] = HCont.HistogramContainer(all_bins[plot_var])\n",
    "    histos['cutflow_incl'][bkg] = np.zeros(len(numCuts))\n",
    "    histos['cutflow_excl'][bkg] = np.zeros(len(numCuts))\n",
    "    histos['sumgenwgt'][bkg] = 0.0\n",
    "    \n",
    "    ### Load data\n",
    "    file_counter = 1\n",
    "    for file in files[bkg][slice(0,MAX_FILES)]:\n",
    "        \n",
    "        if file_counter % 10 == 1:\n",
    "            print(f'Reading file {file_counter} of {len(files[bkg])},'\n",
    "                  f' global {global_file_counter} of {num_files_total}'\n",
    "                  f' ({100*(global_file_counter-1)/num_files_total:.2f}%)')\n",
    "            with open('histos_temp.dat', 'wb') as histos_file:\n",
    "                pickle.dump(histos, histos_file)\n",
    "        file_counter += 1\n",
    "        global_file_counter += 1\n",
    "        \n",
    "        ### Open ROOT file and get tree\n",
    "        tree = uproot.open(file)[branch_path + '/cutsTree']\n",
    "        \n",
    "        ### Make pandas dataframes and create all objects that will be passed to histo functions\n",
    "        obj_extractor = OE.ObjectExtractor(tree)\n",
    "        objects = obj_extractor.get_all()\n",
    "            \n",
    "        ## Add to sum of genwgts\n",
    "        histos['sumgenwgt'][bkg] += np.sum(objects['genwgt'])\n",
    "        \n",
    "        ### Calculate histograms and cutflows\n",
    "        histo_maker = HCalc.HistogramCalculator(objects, bkg)\n",
    "            \n",
    "        ### Cutflows\n",
    "        incl, excl = histo_maker.cutflows()\n",
    "        histos['cutflow_incl'][bkg] += incl\n",
    "        histos['cutflow_excl'][bkg] += excl\n",
    "        \n",
    "        ### Histograms\n",
    "        for plot_var in all_plot_vars:\n",
    "            new_hist = eval(f'histo_maker.{plot_var}()')\n",
    "            histos[plot_var][bkg] += new_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "luminosity = 59.97 * 1000 # 1/pb\n",
    "for bkg, properties in bkgs.items():\n",
    "    properties['weight'] = luminosity * properties['xsec'] / histos['sumgenwgt'][bkg]\n",
    "#     except KeyError:\n",
    "#         properties['weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoBPTX 0.0032492156533199053 18456762.0\n"
     ]
    }
   ],
   "source": [
    "for bkg, properties in bkgs.items():\n",
    "    try:\n",
    "        print(bkg, luminosity * properties['xsec'] / histos['sumgenwgt'][bkg], histos['sumgenwgt'][bkg])\n",
    "    except KeyError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('histos_bkgs_objects_gbm.dat', 'wb') as histos_file:\n",
    "    pickle.dump(histos, histos_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bkg_grps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9875cc6062be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcutFlowInclGrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbkg_grps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'60p0'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'5p25'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'52p5'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'6p0'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbkg_grps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcutFlowInclGrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bkg_grps' is not defined"
     ]
    }
   ],
   "source": [
    "cutFlowInclGrp = {}\n",
    "for grp in bkg_grps:\n",
    "    if '60p0' in grp or '5p25' in grp or '52p5' in grp or '6p0' in grp: continue\n",
    "    for bkg in bkg_grps[grp]:\n",
    "        if grp in cutFlowInclGrp.keys():\n",
    "            cutFlowInclGrp[grp] += histos['cutflow_incl'][bkg].astype(int)\n",
    "        else:\n",
    "            cutFlowInclGrp[grp] = histos['cutflow_incl'][bkg].astype(int)\n",
    "\n",
    "pd.DataFrame.from_dict(cutFlowInclGrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bkg_grps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ce631f69abd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcutFlowInclGrp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbkg_grps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     if '60p0' in grp or '5p25' in grp or '52p5' in grp or '6p0' in grp: continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbkg_grps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcutFlowInclGrp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bkg_grps' is not defined"
     ]
    }
   ],
   "source": [
    "cutFlowInclGrp2 = {}\n",
    "for grp in bkg_grps:\n",
    "#     if '60p0' in grp or '5p25' in grp or '52p5' in grp or '6p0' in grp: continue\n",
    "    for bkg in bkg_grps[grp]:\n",
    "        if grp in cutFlowInclGrp2.keys():\n",
    "            try:\n",
    "                cutFlowInclGrp2[grp] += (histos['cutflow_incl'][bkg]*bkgs[bkg]['weight']).astype(int)\n",
    "            except KeyError: pass\n",
    "        else:\n",
    "            try:\n",
    "                cutFlowInclGrp2[grp] = (histos['cutflow_incl'][bkg]*bkgs[bkg]['weight']).astype(int)\n",
    "            except KeyError: pass\n",
    "\n",
    "\n",
    "pd.DataFrame.from_dict(cutFlowInclGrp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
